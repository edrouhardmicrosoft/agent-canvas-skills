# Design Review Skill - Implementation Tasks

> **Hero Feature**: Spec-driven design review with visual annotations, interactive compliance checking, and automated task generation.

---

## Implementation Status

| Phase | Description | Status |
|-------|-------------|--------|
| Phase 1 | Core Review Engine | âœ… Complete |
| Phase 2 | Annotation & Output | âœ… Complete |
| Phase 3 | Interactive Mode | ğŸ”² Pending |
| Phase 4 | Comparison Features | ğŸ”² Pending |
| Phase 5 | Smart Features | ğŸ”² Pending |

---

## Phase 1: Core Review Engine âœ…

| Task | Description | Status |
|------|-------------|--------|
| Markdown spec parser | `spec_loader.py` - Parse specs with YAML frontmatter and inheritance | âœ… |
| Default spec | `specs/default.md` - 4 pillars, 21 checks | âœ… |
| Basic issue detection | Integration with axe-core for a11y, contrast checking | âœ… |
| CLI with `review` command | `design_review.py review <url> [options]` | âœ… |
| CLI with `specs` command | `design_review.py specs --list|--validate|--show` | âœ… |
| JSON output format | Structured output with summary, issues, artifacts | âœ… |
| Project spec discovery | Auto-discover `DESIGN-SPEC.md` in project root | âœ… |
| Spec inheritance | `extends: default.md` in frontmatter | âœ… |

**Files created:**
- `.claude/skills/design-review/scripts/spec_loader.py`
- `.claude/skills/design-review/scripts/design_review.py`
- `.claude/skills/design-review/specs/default.md`
- `.claude/skills/design-review/specs/README.md`
- `.claude/skills/design-review/SKILL.md`

---

## Phase 2: Annotation & Output âœ…

| Task | Description | Status |
|------|-------------|--------|
| Screenshot annotator | `annotator.py` - Draw on screenshots using Pillow | âœ… |
| Numbered circles | â‘ â‘¡â‘¢ markers at issue locations | âœ… |
| Severity colors | Red (blocking), orange (major), yellow (minor) | âœ… |
| Border drawing | Borders around problematic elements | âœ… |
| Legend | Issue list at bottom of annotated screenshot | âœ… |
| Enhanced DESIGN-REVIEW-TASKS.md | Better formatting with issue numbers, source hints | âœ… |
| Annotated screenshot reference | Include annotated.png reference in tasks file | âœ… |
| Source file detection | Heuristics to detect likely source files | âœ… |
| Code fix examples | Suggested fixes with code examples | âœ… |
| Session artifacts | Full directory structure with session.json | âœ… |
| Wire --annotate flag | Connect flag to annotator module | âœ… |

**Files created/modified:**
- `.claude/skills/design-review/scripts/annotator.py` (NEW)
- `.claude/skills/design-review/scripts/design_review.py` (enhanced)

**Session artifacts structure:**
```
.canvas/reviews/<sessionId>/
â”œâ”€â”€ session.json       # Full event log + metadata
â”œâ”€â”€ report.json        # Structured issue data
â”œâ”€â”€ screenshot.png     # Original screenshot
â””â”€â”€ annotated.png      # Screenshot with redlines (when --annotate used)
```

---

## Phase 3: Interactive Mode ğŸ”²

| Task | Description | Status |
|------|-------------|--------|
| Review overlay JS | Browser overlay styled for review (not editing) | ğŸ”² |
| Compliance indicators | Show âœ…âš ï¸âŒ as user hovers over elements | ğŸ”² |
| Element-specific review | Click element â†’ full compliance report | ğŸ”² |
| "Add to Review" workflow | User curates which issues to include | ğŸ”² |
| "Next Issue" navigation | Jump to next non-compliant element | ğŸ”² |
| Browser close handling | Generate report when browser closes | ğŸ”² |

**Expected CLI:**
```bash
uv run .claude/skills/design-review/scripts/design_review.py interactive http://localhost:3000
```

---

## Phase 4: Comparison Features ğŸ”²

| Task | Description | Status |
|------|-------------|--------|
| Reference image comparison | Compare against images in `imgs/` folder | ğŸ”² |
| `image_comparator.py` | Visual diff algorithm (SSIM or pixel diff) | ğŸ”² |
| Visual diff output | Highlight differences between current and reference | ğŸ”² |
| Figma MCP integration | Optional: fetch frames from Figma API | ğŸ”² |
| Compare command | `design_review.py compare <url> --reference <img>` | ğŸ”² |

**Expected CLI:**
```bash
uv run .claude/skills/design-review/scripts/design_review.py compare http://localhost:3000 --reference imgs/homepage.png
```

---

## Phase 5: Smart Features ğŸ”²

| Task | Description | Status |
|------|-------------|--------|
| User prompt parsing | Natural language â†’ review type | ğŸ”² |
| Intent detection | "check buttons" â†’ filter to button-related checks | ğŸ”² |
| Editable context detection | Detect if source files are available | ğŸ”² |
| Source file mapping | Map selectors to actual source files | ğŸ”² |
| todowrite integration | Create todos for each issue | ğŸ”² |
| Interactive prompts | Prompt user for review type if not specified | ğŸ”² |

**Expected flow:**
```
$ uv run design_review.py http://localhost:3000

ğŸ¨ Design Review - What would you like to check?

  1. Full page review (check entire page against spec)
  2. Specific element (select an element to review)
  3. Compare to reference (compare against design image)
  4. Accessibility audit (deep-dive a11y checks)
  5. Custom (describe what you're looking for)

Enter choice [1-5] or describe your goal: 
```

---

## Commands Reference

```bash
SKILL_DIR=".claude/skills/design-review/scripts"

# === REVIEW COMMANDS ===
uv run $SKILL_DIR/design_review.py review <url>                    # Basic review
uv run $SKILL_DIR/design_review.py review <url> --spec my-spec.md  # Custom spec
uv run $SKILL_DIR/design_review.py review <url> --selector ".hero" # Specific element
uv run $SKILL_DIR/design_review.py review <url> --annotate         # With annotations
uv run $SKILL_DIR/design_review.py review <url> --generate-tasks   # With task file

# === SPEC MANAGEMENT ===
uv run $SKILL_DIR/design_review.py specs --list                    # List specs
uv run $SKILL_DIR/design_review.py specs --validate my-spec.md     # Validate spec
uv run $SKILL_DIR/design_review.py specs --show default.md         # Show spec details

# === TESTING ===
npm run dev                                                         # Start dev server
uv run $SKILL_DIR/design_review.py review http://localhost:3000 --annotate --generate-tasks
```

---

## Design Decisions Made

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Spec format | Markdown + YAML frontmatter | Human-readable, easy to version control |
| Annotation style | Numbered circles + severity colors | Both numbers (for reference) and colors (for scanning) |
| Session ID format | `review_YYYYMMDDHHMMSS###` | Timestamp-based, sortable |
| Screenshot in legend | Yes, with issue list | Provides visual reference alongside annotations |
| Source file detection | Heuristic-based | data-testid, class names, common patterns |
| Code examples | Per check-id lookup | Extensible dictionary of common fixes |

---

## Open Questions (Future Phases)

1. **Interactive overlay UX**: Mini compliance card vs simple icon on hover?
2. **Agent-canvas integration**: Separate entry point or `--mode review` flag?
3. **Figma auth**: How to handle Figma API authentication for comparison?
4. **Real-time checks**: Run checks as page loads or only on demand?

---

## Files Overview

```
.claude/skills/design-review/
â”œâ”€â”€ SKILL.md                     # Skill documentation
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ design_review.py         # Main CLI (review, specs commands)
â”‚   â”œâ”€â”€ spec_loader.py           # Markdown spec parser
â”‚   â””â”€â”€ annotator.py             # Screenshot annotation
â”œâ”€â”€ specs/
â”‚   â”œâ”€â”€ default.md               # Default spec (4 pillars, 21 checks)
â”‚   â””â”€â”€ README.md                # Spec format documentation
â””â”€â”€ imgs/
    â””â”€â”€ README.md                # Reference image documentation (future)
```
